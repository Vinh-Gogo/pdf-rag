"""
Pipeline hoÃ n chá»‰nh: PDF -> Split Pages -> Extract Text -> Vector Store

Quy trÃ¬nh:
1. Cáº¯t PDF thÃ nh 168 trang Ä‘Æ¡n láº» (hoáº·c sá»‘ trang chá»‰ Ä‘á»‹nh)
2. TrÃ­ch xuáº¥t text tá»« má»—i trang
3. LÆ°u text vÃ o Qdrant Vector Store
4. Test retrieval
"""

import os
import sys
from pathlib import Path
from typing import Optional

# Add project root to path
script_dir = Path(__file__).resolve().parent
project_root = script_dir.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.helpers.PDFText import PDFTextExtractor
from helpers.vectorstore_from_pages import (
    read_pages_from_directory,
    save_pages_to_json,
    store_pages_in_qdrant_direct,
    retrieve_similar_pages,
    display_page_retrieval_results
)


def run_complete_pipeline(
    pdf_path: str,
    start_page: int = 1,
    end_page: Optional[int] = None,
    max_pages: int = 168,
    collection_name: str = "esg_pages",
    skip_split: bool = False,
    skip_extract: bool = False,
    skip_vectorstore: bool = False
):
    """
    Cháº¡y pipeline hoÃ n chá»‰nh tá»« PDF Ä‘áº¿n Vector Store
    
    Args:
        pdf_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file PDF
        start_page (int): Trang báº¯t Ä‘áº§u (1-based)
        end_page (Optional[int]): Trang káº¿t thÃºc (1-based). None = táº¥t cáº£
        max_pages (int): Sá»‘ trang tá»‘i Ä‘a xá»­ lÃ½
        collection_name (str): TÃªn collection trong Qdrant
        skip_split (bool): Bá» qua bÆ°á»›c cáº¯t PDF (náº¿u Ä‘Ã£ cáº¯t rá»“i)
        skip_extract (bool): Bá» qua bÆ°á»›c trÃ­ch xuáº¥t text (náº¿u Ä‘Ã£ cÃ³ file text)
        skip_vectorstore (bool): Bá» qua bÆ°á»›c lÆ°u vÃ o vector store (chá»‰ xá»­ lÃ½ PDF)
    
    Returns:
        bool: True náº¿u thÃ nh cÃ´ng
    """
    
    # Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n
    output_text_dir = project_root / "src" / "data" / "raw"
    output_pdf_dir = project_root / "src" / "data" / "pdfs" / "pages"
    output_json_dir = project_root / "src" / "data" / "push"
    
    print("="*80)
    print("ğŸš€ PDF TO VECTOR STORE PIPELINE")
    print("="*80)
    print(f"ğŸ“– PDF: {pdf_path}")
    print(f"ğŸ“Š Range: Page {start_page} - {end_page if end_page else 'END'}")
    print(f"ğŸ“ Max pages: {max_pages}")
    print(f"ğŸ—„ï¸ Collection: {collection_name}")
    print("="*80)
    
    # Initialize extractor
    extractor = PDFTextExtractor(
        pdf_path=pdf_path,
        output_dir=str(output_text_dir),
        split_output_dir=str(output_pdf_dir)
    )
    
    # Get total pages
    total_pages = extractor.get_page_count()
    if total_pages == 0:
        print("âŒ KhÃ´ng thá»ƒ má»Ÿ PDF hoáº·c PDF rá»—ng")
        return False
    
    # Calculate actual end page
    if end_page is None:
        end_page = min(total_pages, max_pages)
    else:
        end_page = min(end_page, total_pages, max_pages)
    
    actual_pages = end_page - start_page + 1
    print(f"ğŸ“„ Sáº½ xá»­ lÃ½ {actual_pages} trang (tá»« {start_page} Ä‘áº¿n {end_page})")
    
    # ============================================================================
    # STEP 1: Split PDF into individual pages
    # ============================================================================
    if not skip_split:
        print(f"\n{'='*80}")
        print("BÆ¯á»šC 1: Cáº®T PDF THÃ€NH CÃC TRANG ÄÆ N Láºº")
        print("="*80)
        
        split_success = extractor.split_pdf_into_pages(
            start_page=start_page,
            end_page=end_page
        )
        
        if not split_success:
            print("âŒ Lá»—i khi cáº¯t PDF")
            return False
        
        print(f"âœ… ÄÃ£ cáº¯t {actual_pages} trang vÃ o {output_pdf_dir}")
    else:
        print(f"\nâ­ï¸ Bá» qua BÆ¯á»šC 1: Cáº¯t PDF (skip_split=True)")
    
    # ============================================================================
    # STEP 2: Extract text from each page
    # ============================================================================
    if not skip_extract:
        print(f"\n{'='*80}")
        print("BÆ¯á»šC 2: TRÃCH XUáº¤T TEXT Tá»ª Má»–I TRANG")
        print("="*80)
        
        extract_success = extractor.extract_all_pages(
            start_page=start_page,
            end_page=end_page,
            clean_text=True
        )
        
        if not extract_success:
            print("âŒ Lá»—i khi trÃ­ch xuáº¥t text")
            return False
        
        print(f"âœ… ÄÃ£ trÃ­ch xuáº¥t text tá»« {actual_pages} trang vÃ o {output_text_dir}")
    else:
        print(f"\nâ­ï¸ Bá» qua BÆ¯á»šC 2: TrÃ­ch xuáº¥t text (skip_extract=True)")
    
    # ============================================================================
    # STEP 3: Read pages and prepare for vector store
    # ============================================================================
    if not skip_vectorstore:
        print(f"\n{'='*80}")
        print("BÆ¯á»šC 3: CHUáº¨N Bá»Š Dá»® LIá»†U CHO VECTOR STORE")
        print("="*80)
        
        pages = read_pages_from_directory(str(output_text_dir))
        
        if not pages:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y pages Ä‘á»ƒ xá»­ lÃ½")
            return False
        
        # Filter pages by range
        pages = [p for p in pages if start_page <= int(p['page_index']) <= end_page]
        
        print(f"âœ… ÄÃ£ Ä‘á»c {len(pages)} pages")
        
        # Display statistics
        total_words = sum(int(p['word_count']) for p in pages)
        print(f"\nğŸ“Š THá»NG KÃŠ:")
        print(f"   Tá»•ng pages: {len(pages)}")
        print(f"   Tá»•ng tá»«: {total_words:,}")
        print(f"   Trung bÃ¬nh: {total_words/len(pages):.1f} tá»«/page")
        
        # Save to JSON
        output_json_dir.mkdir(parents=True, exist_ok=True)
        output_json_file = output_json_dir / "pages_data.json"
        save_pages_to_json(pages, str(output_json_file))
        
        # ============================================================================
        # STEP 4: Store in Qdrant Vector Store
        # ============================================================================
        print(f"\n{'='*80}")
        print("BÆ¯á»šC 4: LÆ¯U VÃ€O QDRANT VECTOR STORE")
        print("="*80)
        
        try:
            vectorstore = store_pages_in_qdrant_direct(pages, collection_name)
            print(f"âœ… ÄÃ£ lÆ°u {len(pages)} pages vÃ o collection '{collection_name}'")
            
            # ============================================================================
            # STEP 5: Test retrieval
            # ============================================================================
            print(f"\n{'='*80}")
            print("BÆ¯á»šC 5: TEST RETRIEVAL")
            print("="*80)
            
            test_queries = [
                "vá»‘n Ä‘iá»u lá»‡ cá»§a cÃ´ng ty",
                "bÃ¡o cÃ¡o tÃ i chÃ­nh",
                "hoáº¡t Ä‘á»™ng kinh doanh chÃ­nh",
                "quáº£n trá»‹ rá»§i ro"
            ]
            
            for query in test_queries:
                print(f"\nğŸ” Query: '{query}'")
                results = retrieve_similar_pages(query, vectorstore, top_k=3)
                
                for i, result in enumerate(results, 1):
                    print(f"\n  {i}. Page {result['page_index']} (Score: {result['similarity_score']:.4f})")
                    print(f"     {result['content'][:150]}...")
                
                print("-" * 80)
            
        except Exception as e:
            print(f"âŒ Lá»—i khi lÆ°u vÃ o vector store: {e}")
            return False
    else:
        print(f"\nâ­ï¸ Bá» qua BÆ¯á»šC 3-5: Vector store (skip_vectorstore=True)")
    
    # ============================================================================
    # FINAL SUMMARY
    # ============================================================================
    print(f"\n{'='*80}")
    print("âœ… PIPELINE HOÃ€N THÃ€NH!")
    print("="*80)
    print(f"ğŸ“ Text files: {output_text_dir}")
    print(f"ğŸ“ PDF pages: {output_pdf_dir}")
    if not skip_vectorstore:
        print(f"ğŸ—„ï¸ Vector store collection: {collection_name}")
    print("="*80)
    
    return True


# ============================================================================
# MAIN EXECUTION
# ============================================================================
if __name__ == "__main__":
    # Cáº¥u hÃ¬nh
    PDF_PATH = project_root / "src" / "data" / "pdfs" / "file_2.pdf"
    START_PAGE = 1
    END_PAGE = 168  # None Ä‘á»ƒ xá»­ lÃ½ táº¥t cáº£
    MAX_PAGES = 168
    COLLECTION_NAME = "esg_pages"
    
    # CÃ¡c flags Ä‘á»ƒ bá» qua cÃ¡c bÆ°á»›c (náº¿u Ä‘Ã£ cháº¡y rá»“i)
    SKIP_SPLIT = False      # True náº¿u Ä‘Ã£ cáº¯t PDF rá»“i
    SKIP_EXTRACT = False    # True náº¿u Ä‘Ã£ trÃ­ch xuáº¥t text rá»“i
    SKIP_VECTORSTORE = False  # True náº¿u chá»‰ muá»‘n xá»­ lÃ½ PDF
    
    success = run_complete_pipeline(
        pdf_path=str(PDF_PATH),
        start_page=START_PAGE,
        end_page=END_PAGE,
        max_pages=MAX_PAGES,
        collection_name=COLLECTION_NAME,
        skip_split=SKIP_SPLIT,
        skip_extract=SKIP_EXTRACT,
        skip_vectorstore=SKIP_VECTORSTORE
    )
    
    if success:
        print("\nğŸ‰ Táº¥t cáº£ cÃ¡c bÆ°á»›c Ä‘Ã£ hoÃ n thÃ nh thÃ nh cÃ´ng!")
    else:
        print("\nâŒ Pipeline gáº·p lá»—i. Vui lÃ²ng kiá»ƒm tra log.")
