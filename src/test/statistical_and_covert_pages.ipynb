{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f641a7b1",
   "metadata": {},
   "source": [
    "# show all pages\n",
    "\n",
    "```text\n",
    "all pages pdf (type: png) in path: data/pages\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install PyMuPDF matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e110835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ ƒê√£ l∆∞u 168 ·∫£nh, b·∫Øt ƒë·∫ßu hi·ªÉn th·ªã...\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# === 1. Render t·∫•t c·∫£ c√°c trang th√†nh ·∫£nh ===\n",
    "pdf_path = \"../data/pdfs/file_2.pdf\"\n",
    "output_folder = \"../data/images\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "pdf_file = fitz.open(pdf_path)\n",
    "zoom = 2  # 2 = 144 DPI, c√≥ th·ªÉ tƒÉng l√™n n·∫øu c·∫ßn n√©t h∆°n\n",
    "mat = fitz.Matrix(zoom, zoom)\n",
    "\n",
    "saved_images = []\n",
    "\n",
    "for page_index in range(len(pdf_file)):\n",
    "    page = pdf_file[page_index]\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    output_path = os.path.join(output_folder, f\"page_{page_index + 1}.png\")\n",
    "    pix.save(output_path)\n",
    "    saved_images.append(output_path)\n",
    "\n",
    "pdf_file.close()\n",
    "\n",
    "# === 2. Hi·ªÉn th·ªã T·∫§T C·∫¢ ·∫£nh b·∫±ng matplotlib ===\n",
    "print(f\"üìÇ ƒê√£ l∆∞u {len(saved_images)} ·∫£nh, b·∫Øt ƒë·∫ßu hi·ªÉn th·ªã...\")\n",
    "\n",
    "# # Thi·∫øt l·∫≠p l∆∞·ªõi: 12 c·ªôt, bao nhi√™u h√†ng t√πy s·ªë ·∫£nh\n",
    "# cols = 6\n",
    "# rows = (len(saved_images) + cols - 1) // cols\n",
    "\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 2.5))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, img_path in zip(axes, saved_images):\n",
    "#     img = Image.open(img_path)\n",
    "#     ax.imshow(img)\n",
    "#     ax.axis(\"off\")\n",
    "#     ax.set_title(os.path.basename(img_path).split(\"_\")[1], fontsize=6, pad=2)\n",
    "\n",
    "# # ·∫®n c√°c √¥ th·ª´a\n",
    "# for ax in axes[len(saved_images):]:\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251618d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================\n",
    "# üîπ ƒê∆∞·ªùng d·∫´n\n",
    "# ==========================\n",
    "input_folder = Path(\"../src/data/ground_struct/pages_images\")\n",
    "output_folder = Path(\"../src/data/ground_struct/pages_images_processed\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# üîπ H√†m ti·ªÅn x·ª≠ l√Ω ƒë∆°n gi·∫£n\n",
    "# ==========================\n",
    "def simple_threshold(image_path, output_path):\n",
    "    \"\"\"\n",
    "    Ch·ªâ grayscale + threshold ƒë∆°n gi·∫£n\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c: {image_path}\")\n",
    "    \n",
    "    # 1. Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2. Otsu threshold (t·ª± ƒë·ªông t√¨m ng∆∞·ª°ng t·ªëi ∆∞u)\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # 3. ƒê·∫£o m√†u n·∫øu n·ªÅn ƒëen\n",
    "    if np.mean(binary) < 127:\n",
    "        binary = cv2.bitwise_not(binary)\n",
    "    \n",
    "    cv2.imwrite(str(output_path), binary)\n",
    "    return binary\n",
    "\n",
    "# ==========================\n",
    "# üîπ X·ª≠ l√Ω batch\n",
    "# ==========================\n",
    "processed = 0\n",
    "failed = []\n",
    "\n",
    "for img_file in sorted(input_folder.glob(\"page_*.png\")):\n",
    "    output_path = output_folder / img_file.name\n",
    "    \n",
    "    try:\n",
    "        simple_threshold(img_file, output_path)\n",
    "        processed += 1\n",
    "        print(f\"‚úÖ {img_file.name}\")\n",
    "    except Exception as e:\n",
    "        failed.append(img_file.name)\n",
    "        print(f\"‚ùå {img_file.name}: {e}\")\n",
    "\n",
    "print(f\"\\nüìä ƒê√£ x·ª≠ l√Ω: {processed} ‚Üí {output_folder}\")\n",
    "if failed:\n",
    "    print(f\"‚ùå Th·∫•t b·∫°i: {failed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "input_folder = Path(\"../src/data/ground_struct/pages_images\")\n",
    "output_folder = Path(\"../src/data/ground_struct/pages_images_processed\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def threshold_methods(image_path, output_path, method=\"otsu\"):\n",
    "    \"\"\"\n",
    "    method: 'otsu', 'adaptive_mean', 'adaptive_gaussian', 'simple'\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if method == \"otsu\":\n",
    "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    elif method == \"adaptive_mean\":\n",
    "        binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                      cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    elif method == \"adaptive_gaussian\":\n",
    "        binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                      cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    elif method == \"simple\":\n",
    "        _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Method kh√¥ng h·ª£p l·ªá: {method}\")\n",
    "    \n",
    "    # ƒê·∫£o m√†u n·∫øu c·∫ßn\n",
    "    if np.mean(binary) < 127:\n",
    "        binary = cv2.bitwise_not(binary)\n",
    "    \n",
    "    cv2.imwrite(str(output_path), binary)\n",
    "    return binary\n",
    "\n",
    "# X·ª≠ l√Ω batch\n",
    "processed = 0\n",
    "failed = []\n",
    "\n",
    "for img_file in sorted(input_folder.glob(\"page_*.png\")):\n",
    "    output_path = output_folder / img_file.name\n",
    "    \n",
    "    try:\n",
    "        # Th·ª≠ Otsu tr∆∞·ªõc\n",
    "        threshold_methods(img_file, output_path, method=\"otsu\")\n",
    "        processed += 1\n",
    "        print(f\"‚úÖ {img_file.name}\")\n",
    "    except Exception as e1:\n",
    "        try:\n",
    "            # Fallback: Adaptive Gaussian\n",
    "            threshold_methods(img_file, output_path, method=\"adaptive_gaussian\")\n",
    "            processed += 1\n",
    "            print(f\"‚úÖ {img_file.name} (adaptive)\")\n",
    "        except Exception as e2:\n",
    "            failed.append(img_file.name)\n",
    "            print(f\"‚ùå {img_file.name}: {e2}\")\n",
    "\n",
    "print(f\"\\nüìä ƒê√£ x·ª≠ l√Ω: {processed} ‚Üí {output_folder}\")\n",
    "if failed:\n",
    "    print(f\"‚ùå Th·∫•t b·∫°i: {failed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751be95",
   "metadata": {},
   "source": [
    "# all page + all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2be6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === 1. Render to√†n b·ªô trang th√†nh ·∫£nh ===\n",
    "pdf_path = \"../src/data/ground_struct/file_2.pdf\"\n",
    "output_pages = \"../src/data/ground_struct/pages_images\"\n",
    "output_embedded = \"../data/images\"\n",
    "os.makedirs(output_pages, exist_ok=True)\n",
    "os.makedirs(output_embedded, exist_ok=True)\n",
    "\n",
    "pdf_file = fitz.open(pdf_path)\n",
    "zoom = 4\n",
    "mat = fitz.Matrix(zoom, zoom)\n",
    "\n",
    "saved_pages = []\n",
    "saved_embedded = []\n",
    "\n",
    "# --- Render trang ---\n",
    "for page_index in range(len(pdf_file)):\n",
    "    page = pdf_file[page_index]\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    page_path = os.path.join(output_pages, f\"page_{page_index + 1}.png\")\n",
    "    pix.save(page_path)\n",
    "    saved_pages.append(page_path)\n",
    "\n",
    "# --- Tr√≠ch xu·∫•t ·∫£nh nh√∫ng ---\n",
    "for page_index in range(len(pdf_file)):\n",
    "    page = pdf_file[page_index]\n",
    "    image_list = page.get_images(full=True)\n",
    "    if image_list:\n",
    "        print(f\"[+] Page {page_index + 1}: {len(image_list)} embedded image(s)\")\n",
    "        for img_index, img in enumerate(image_list, start=1):\n",
    "            xref = img[0]\n",
    "            base_image = pdf_file.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_name = f\"page_{page_index + 1}_image_{img_index}.{image_ext}\"\n",
    "            image_path = os.path.join(output_embedded, image_name)\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "            saved_embedded.append(image_path)\n",
    "    else:\n",
    "        print(f\"[!] Page {page_index + 1}: no embedded images\")\n",
    "\n",
    "pdf_file.close()\n",
    "\n",
    "# === 2. Hi·ªÉn th·ªã t·∫•t c·∫£ ·∫£nh nh√∫ng b·∫±ng matplotlib ===\n",
    "print(f\"üìÇ ƒê√£ l∆∞u {len(saved_embedded)} ·∫£nh nh√∫ng, b·∫Øt ƒë·∫ßu hi·ªÉn th·ªã...\")\n",
    "\n",
    "cols = 6\n",
    "rows = (len(saved_embedded) + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 2.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img_path in zip(axes, saved_embedded):\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(os.path.basename(img_path), fontsize=6, pad=2)\n",
    "\n",
    "# ·∫®n √¥ th·ª´a\n",
    "for ax in axes[len(saved_embedded):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c79fa1",
   "metadata": {},
   "source": [
    "# all contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "pdf_path = \"../src/data/ground_struct/file_2.pdf\"\n",
    "output_dir = \"../src/data/contents\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pdf_file = fitz.open(pdf_path)\n",
    "\n",
    "blocks = [] #  L∆∞u tr·ªØ t·∫•t c·∫£ c√°c block vƒÉn b·∫£n theo m·ªói page\n",
    "\n",
    "for page_number in range(1, len(pdf_file) + 1):\n",
    "    page = pdf_file[page_number - 1]\n",
    "    text = page.get_text(\"text\")\n",
    "    text_blocks = page.get_text_blocks()\n",
    "    text_path = os.path.join(output_dir, f\"page_{page_number}.txt\")\n",
    "    with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for block in text_blocks:\n",
    "            f.write(block[4])  # Write the text content of each block\n",
    "            blocks.append(np.array([block]))  # L∆∞u block v√†o danh s√°ch\n",
    "    print(f\"‚úÖ Saved page_{page_number}.txt\")\n",
    "\n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab22bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "blocks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================\n",
    "# üîπ ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n\n",
    "# ==========================\n",
    "input_folder = Path(\"../src/data/ground_struct/pages_images\")\n",
    "output_folder = Path(\"../src/data/ground_struct/pages_images_processed\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# üîπ Advanced Grayscale\n",
    "# ==========================\n",
    "def advanced_grayscale(img):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ·∫£nh m√†u sang grayscale th√¥ng minh, gi·ªØ ƒë·ªô t∆∞∆°ng ph·∫£n cao\n",
    "    v√† chi ti·∫øt ch·ªØ t·ª´ v√πng m√†u kh√°c nhau.\n",
    "    \"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    L, A, B = cv2.split(lab)\n",
    "\n",
    "    # TƒÉng c∆∞·ªùng ƒë·ªô s√°ng (CLAHE ch·ªâ tr√™n k√™nh L)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "    L_enhanced = clahe.apply(L)\n",
    "\n",
    "    # K·∫øt h·ª£p l·∫°i v√† chuy·ªÉn sang grayscale\n",
    "    lab_enhanced = cv2.merge([L_enhanced, A, B])\n",
    "    bgr_enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n",
    "    gray = cv2.cvtColor(bgr_enhanced, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # C·∫£i thi·ªán t∆∞∆°ng ph·∫£n c·ª•c b·ªô\n",
    "    gray = cv2.addWeighted(gray, 1.5, cv2.GaussianBlur(gray, (0, 0), 3), -0.5, 0)\n",
    "    return gray\n",
    "\n",
    "# ==========================\n",
    "# üîπ Ph∆∞∆°ng ph√°p ch√≠nh\n",
    "# ==========================\n",
    "def preprocess_for_ocr(image_path, output_path):\n",
    "    \"\"\"\n",
    "    Ti·ªÅn x·ª≠ l√Ω ·∫£nh t·ªëi ∆∞u cho OCR ti·∫øng Vi·ªát (tƒÉng ƒë·ªô r√µ n√©t, gi·∫£m nhi·ªÖu, gi·ªØ c·∫•u tr√∫c vƒÉn b·∫£n)\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}\")\n",
    "\n",
    "    # 1. Grayscale n√¢ng cao\n",
    "    gray = advanced_grayscale(img)\n",
    "\n",
    "    # 2. Resize n·∫øu ·∫£nh nh·ªè\n",
    "    height, width = gray.shape\n",
    "    if height < 1200 or width < 1200:\n",
    "        scale_factor = max(1200/height, 1200/width)\n",
    "        gray = cv2.resize(gray, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # 3. Kh·ª≠ nhi·ªÖu nh·∫π nh√†ng nh∆∞ng gi·ªØ bi√™n ch·ªØ\n",
    "    denoised = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "\n",
    "    # 4. TƒÉng c∆∞·ªùng ƒë·ªô t∆∞∆°ng ph·∫£n b·∫±ng CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "\n",
    "    # 5. L√†m s·∫Øc n√©t (kernel t·ª± nhi√™n, kh√¥ng qu√° m·∫°nh)\n",
    "    kernel_sharpen = np.array([[0, -1, 0],\n",
    "                               [-1, 5, -1],\n",
    "                               [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(enhanced, -1, kernel_sharpen)\n",
    "\n",
    "    # 6. Adaptive Threshold - x·ª≠ l√Ω √°nh s√°ng kh√¥ng ƒë·ªÅu\n",
    "    binary = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 15, 2)\n",
    "\n",
    "    # 7. L√†m s·∫°ch nhi·ªÖu nh·ªè, n·ªëi n√©t ch·ªØ\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # 8. Ki·ªÉm tra n·ªÅn s√°ng/t·ªëi ƒë·ªÉ ƒë·∫£o m√†u n·∫øu c·∫ßn\n",
    "    if np.mean(cleaned) < 127:\n",
    "        cleaned = cv2.bitwise_not(cleaned)\n",
    "\n",
    "    cv2.imwrite(str(output_path), cleaned)\n",
    "    return cleaned\n",
    "\n",
    "# ==========================\n",
    "# üîπ Ph∆∞∆°ng ph√°p thay th·∫ø\n",
    "# ==========================\n",
    "def preprocess_for_ocr_alternative(image_path, output_path):\n",
    "    \"\"\"\n",
    "    Phi√™n b·∫£n ƒë∆°n gi·∫£n, v·∫´n hi·ªáu qu·∫£ cho t√†i li·ªáu s√°ng m√†u ho·∫∑c c√≥ v√πng m√†u ƒë·ªìng ƒë·ªÅu.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}\")\n",
    "\n",
    "    gray = advanced_grayscale(img)\n",
    "\n",
    "    # Resize n·∫øu c·∫ßn\n",
    "    height, width = gray.shape\n",
    "    if height < 1000:\n",
    "        scale_factor = 1000 / height\n",
    "        gray = cv2.resize(gray, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # C√¢n b·∫±ng histogram to√†n c·ª•c\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Kh·ª≠ nhi·ªÖu nhanh\n",
    "    denoised = cv2.fastNlMeansDenoising(equalized, None, h=8, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "    # L√†m s·∫Øc n√©t nh·∫π\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, kernel)\n",
    "\n",
    "    cv2.imwrite(str(output_path), sharpened)\n",
    "    return sharpened\n",
    "\n",
    "# ==========================\n",
    "# üîπ Ch·∫°y batch\n",
    "# ==========================\n",
    "processed_count = 0\n",
    "failed_files = []\n",
    "\n",
    "for img_file in sorted(input_folder.glob(\"page_*.png\")):\n",
    "    output_path = output_folder / img_file.name\n",
    "\n",
    "    try:\n",
    "        preprocess_for_ocr(img_file, output_path)\n",
    "        processed_count += 1\n",
    "        print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω: {img_file.name}\")\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            preprocess_for_ocr_alternative(img_file, output_path)\n",
    "            processed_count += 1\n",
    "            print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω (alt): {img_file.name}\")\n",
    "        except Exception as e2:\n",
    "            failed_files.append(img_file.name)\n",
    "            print(f\"‚ùå L·ªói khi x·ª≠ l√Ω {img_file.name}: {e2}\")\n",
    "\n",
    "print(f\"\\nüìä T·ªïng k·∫øt: ƒê√£ x·ª≠ l√Ω {processed_count} ·∫£nh ‚Üí {output_folder}\")\n",
    "if failed_files:\n",
    "    print(f\"‚ùå Th·∫•t b·∫°i: {len(failed_files)} file: {failed_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90055dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================\n",
    "# üîπ Advanced Grayscale Conversion for OCR on Colored Documents\n",
    "# ==============================================================\n",
    "def advanced_grayscale(image):\n",
    "    \"\"\"\n",
    "    Enhanced grayscale conversion that preserves contrast from colored text,\n",
    "    backgrounds, and icons for optimal OCR accuracy.\n",
    "    \"\"\"\n",
    "    # Convert to LAB color space to separate luminance (L) from color\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    L, A, B = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to L channel (boost local contrast)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "    L_enhanced = clahe.apply(L)\n",
    "\n",
    "    # Recombine LAB and convert back to BGR, then to grayscale\n",
    "    lab_enhanced = cv2.merge([L_enhanced, A, B])\n",
    "    bgr_enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n",
    "    gray = cv2.cvtColor(bgr_enhanced, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Local contrast boost for faint or colored text\n",
    "    gray = cv2.addWeighted(gray, 1.5, cv2.GaussianBlur(gray, (0, 0), 3), -0.5, 0)\n",
    "    return gray\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# üîπ Multi-Scale OCR Preprocessing\n",
    "# ==============================================================\n",
    "def preprocess_for_ocr_multi_scale(image_path, output_path):\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot read image: {image_path}\")\n",
    "\n",
    "    gray = advanced_grayscale(img)\n",
    "\n",
    "    # Upscale for small text clarity\n",
    "    height, width = gray.shape\n",
    "    upscaled = cv2.resize(gray, (width * 2, height * 2), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Denoising while preserving edges\n",
    "    denoised = cv2.fastNlMeansDenoising(upscaled, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "    # Mild sharpening\n",
    "    kernel_sharpen = np.array([[0, -1, 0],\n",
    "                               [-1, 5, -1],\n",
    "                               [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, kernel_sharpen)\n",
    "\n",
    "    # Adaptive threshold (good for mixed font sizes)\n",
    "    binary = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Morphological cleanup\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    # Invert if necessary\n",
    "    if np.mean(cleaned) < 127:\n",
    "        cleaned = cv2.bitwise_not(cleaned)\n",
    "\n",
    "    cv2.imwrite(str(output_path), cleaned)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# üîπ Large Text (Headings) Optimization\n",
    "# ==============================================================\n",
    "def preprocess_for_large_text(image_path, output_path):\n",
    "    img = cv2.imread(str(image_path))\n",
    "    gray = advanced_grayscale(img)\n",
    "\n",
    "    # Upscale for sharper text edges\n",
    "    height, width = gray.shape\n",
    "    upscaled = cv2.resize(gray, (int(width * 1.5), int(height * 1.5)), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    # Strong contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(upscaled)\n",
    "\n",
    "    # Strong sharpening for bold headings\n",
    "    kernel_sharpen = np.array([[-1, -1, -1],\n",
    "                               [-1,  9, -1],\n",
    "                               [-1, -1, -1]])\n",
    "    sharpened = cv2.filter2D(enhanced, -1, kernel_sharpen)\n",
    "\n",
    "    # Global threshold (Otsu)\n",
    "    _, binary = cv2.threshold(sharpened, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Light morphological cleanup\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    cv2.imwrite(str(output_path), cleaned)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# üîπ Hybrid Method (Balanced for Mixed Fonts)\n",
    "# ==============================================================\n",
    "def preprocess_hybrid(image_path, output_path):\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot read image: {image_path}\")\n",
    "\n",
    "    gray = advanced_grayscale(img)\n",
    "\n",
    "    # Upscale moderately\n",
    "    height, width = gray.shape\n",
    "    upscaled = cv2.resize(gray, (width * 2, height * 2), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Bilateral filter (keeps edges crisp)\n",
    "    denoised = cv2.bilateralFilter(upscaled, 9, 75, 75)\n",
    "\n",
    "    # CLAHE and equalization for uniform brightness\n",
    "    equalized = cv2.equalizeHist(denoised)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.5, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(equalized)\n",
    "\n",
    "    # Unsharp mask (natural sharpening)\n",
    "    gaussian = cv2.GaussianBlur(enhanced, (0, 0), 1.5)\n",
    "    unsharp = cv2.addWeighted(enhanced, 1.8, gaussian, -0.8, 0)\n",
    "\n",
    "    # Adaptive threshold for mixed text sizes\n",
    "    binary = cv2.adaptiveThreshold(unsharp, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 15, 2)\n",
    "\n",
    "    # Morphological cleanup\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Invert if background too dark\n",
    "    if np.mean(cleaned) < 127:\n",
    "        cleaned = cv2.bitwise_not(cleaned)\n",
    "\n",
    "    cv2.imwrite(str(output_path), cleaned)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# üîπ Batch Processing for a Folder\n",
    "# ==============================================================\n",
    "input_folder = Path(\"../src/data/ground_struct/pages_images\")\n",
    "output_folder = Path(\"../src/data/ground_struct/pages_images_processed\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processed_count = 0\n",
    "failed_files = []\n",
    "\n",
    "for img_file in sorted(input_folder.glob(\"page_*.png\")):\n",
    "    output_path = output_folder / img_file.name\n",
    "    try:\n",
    "        preprocess_hybrid(img_file, output_path)\n",
    "        processed_count += 1\n",
    "        print(f\"‚úÖ Processed (hybrid): {img_file.name}\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            preprocess_for_ocr_multi_scale(img_file, output_path)\n",
    "            processed_count += 1\n",
    "            print(f\"‚úÖ Processed (multi-scale): {img_file.name}\")\n",
    "        except Exception:\n",
    "            try:\n",
    "                preprocess_for_large_text(img_file, output_path)\n",
    "                processed_count += 1\n",
    "                print(f\"‚úÖ Processed (large-text): {img_file.name}\")\n",
    "            except Exception as e:\n",
    "                failed_files.append(img_file.name)\n",
    "                print(f\"‚ùå Failed {img_file.name}: {e}\")\n",
    "\n",
    "print(f\"\\nüìä Summary: Processed {processed_count} images ‚Üí {output_folder}\")\n",
    "if failed_files:\n",
    "    print(f\"‚ùå Failed ({len(failed_files)}): {failed_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c0a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n ---\n",
    "# Gi·∫£ s·ª≠ b·∫°n ƒëang ch·∫°y script n√†y t·ª´ th∆∞ m·ª•c cha c·ªßa 'data'\n",
    "content_folder = \"./data/contents\"\n",
    "output_file = \"final_text.txt\"\n",
    "output_path = os.path.join(\"./data\", output_file) # L∆∞u file k·∫øt qu·∫£ v√†o th∆∞ m·ª•c 'data'\n",
    "\n",
    "# --- 1. L·∫•y danh s√°ch c√°c t·ªáp c·∫ßn x·ª≠ l√Ω ---\n",
    "# L·ªçc ch·ªâ l·∫•y c√°c t·ªáp .txt v√† s·∫Øp x·∫øp theo s·ªë trang (v√≠ d·ª•: page_1, page_2...)\n",
    "all_files = os.listdir(content_folder)\n",
    "\n",
    "# H√†m key ƒë·ªÉ s·∫Øp x·∫øp c√°c t·ªáp theo s·ªë trang.\n",
    "# V√≠ d·ª•: \"page_10.txt\" s·∫Ω ƒë·ª©ng sau \"page_9.txt\"\n",
    "def sort_key(filename):\n",
    "    # Tr√≠ch xu·∫•t s·ªë trang t·ª´ t√™n t·ªáp (v√≠ d·ª•: \"page_1.txt\" -> 1)\n",
    "    try:\n",
    "        return int(filename.split('_')[1].split('.')[0])\n",
    "    except:\n",
    "        # ƒê·∫∑t c√°c t·ªáp kh√¥ng theo format n√†y ·ªü cu·ªëi\n",
    "        return float('inf') \n",
    "\n",
    "text_files = sorted(\n",
    "    [f for f in all_files if f.endswith('.txt')],\n",
    "    key=sort_key\n",
    ")\n",
    "\n",
    "# --- 2. Th·ª±c hi·ªán n·ªëi t·ªáp ---\n",
    "print(f\"B·∫Øt ƒë·∫ßu n·ªëi {len(text_files)} t·ªáp t·ª´ '{content_folder}'...\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for filename in text_files:\n",
    "        input_path = os.path.join(content_folder, filename)\n",
    "        \n",
    "        # Th√™m ti√™u ƒë·ªÅ trang (t√πy ch·ªçn, ƒë·ªÉ d·ªÖ ph√¢n bi·ªát n·ªôi dung gi·ªØa c√°c trang)\n",
    "        outfile.write(f\"\\n\")\n",
    "        \n",
    "        try:\n",
    "            with open(input_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "                content = infile.read()\n",
    "                outfile.write(content)\n",
    "                print(f\"‚úÖ ƒê√£ th√™m: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói khi ƒë·ªçc t·ªáp {filename}: {e}\")\n",
    "\n",
    "print(\"\\n--- HO√ÄN T·∫§T ---\")\n",
    "print(f\"T·∫•t c·∫£ n·ªôi dung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43461ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import word_tokenize\n",
    "from typing import List\n",
    "from utils.helper import Helpers\n",
    "\n",
    "helpers = Helpers()\n",
    "\n",
    "def bm25_preprocessing_func(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    First: M√ìN G√Ä, V·ªäT & TR·ª®NG, V·ªãt kho g·ª´ng, Th·ªãt v·ªãt ch·∫∑t kh√∫c, kho c√πng g·ª´ng, m·∫Øm, ƒë∆∞·ªùng cho sƒÉn, V·ªãt, g·ª´ng, m·∫Øm, ƒë∆∞·ªùng, m√≥n m·∫∑n, G·ª´ng n·ªìng, m√πi v·ªãt kho d·∫≠y m√πi, 2-3 ng∆∞·ªùi\n",
    "    Final: ['g√†', 'v·ªãt tr·ª©ng', 'v·ªãt kho g·ª´ng', 'th·ªãt v·ªãt ch·∫∑t kh√∫c', 'kho g·ª´ng', 'm·∫Øm', 'ƒë∆∞·ªùng sƒÉn', 'v·ªãt', 'g·ª´ng', 'm·∫Øm', 'ƒë∆∞·ªùng', 'm·∫∑n', 'g·ª´ng n·ªìng', 'm√πi v·ªãt kho d·∫≠y m√πi', '2 3 ng∆∞·ªùi']\n",
    "    \n",
    "    First: M√ìN G√Ä, V·ªäT & TR·ª®NG, Tr·ª©ng chi√™n th·ªãt, Tr·ª©ng g√† ƒë√°nh tan, tr·ªôn th·ªãt bƒÉm, n√™m gia v·ªã, chi√™n v√†ng, Tr·ª©ng g√†, th·ªãt ba ch·ªâ bƒÉm, m√≥n b√©o, m·∫∑n, Tr·ª©ng chi√™n v√†ng th∆°m, h√†nh l√°, 2-3 ng∆∞·ªùi\n",
    "    Final: ['g√†', 'v·ªãt tr·ª©ng', 'tr·ª©ng chi√™n th·ªãt', 'tr·ª©ng g√† ƒë√°nh tan', 'tr·ªôn th·ªãt bƒÉm', 'n√™m gia v·ªã', 'chi√™n v√†ng', 'tr·ª©ng g√†', 'th·ªãt ba ch·ªâ bƒÉm', 'b√©o', 'm·∫∑n', 'tr·ª©ng chi√™n v√†ng th∆°m', 'h√†nh l√°', '2 3 ng∆∞·ªùi']\n",
    "\n",
    "    First: N∆Ø·ªöC M√ÅT NH√Ä L√ÄM, Tr√† ƒë√°, Tr√† n·∫•u, Tr√†, N∆∞·ªõc, Tr√†, 1 ng∆∞·ªùi\n",
    "    Final: ['n∆∞·ªõc m√°t', 'tr√† ƒë√°', 'tr√† n·∫•u', 'tr√†', 'n∆∞·ªõc', 'tr√†', '1 ng∆∞·ªùi']\n",
    "    \n",
    "    First: N∆Ø·ªöC M√ÅT NH√Ä L√ÄM, Coca / 7 UP, N∆∞·ªõc ng·ªçt c√≥ gas, N∆∞·ªõc ng·ªçt, Soft Drink, Gas, 1 ng∆∞·ªùi\n",
    "    Final: ['n∆∞·ªõc m√°t', 'coca 7 up', 'n∆∞·ªõc ng·ªçt gas', 'n∆∞·ªõc ng·ªçt', 'soft drink', 'gas', '1 ng∆∞·ªùi']\n",
    "    \n",
    "    First: N∆Ø·ªöC M√ÅT NH√Ä L√ÄM, N∆∞·ªõc su·ªëi, N∆∞·ªõc su·ªëi thanh l·ªçc, N∆∞·ªõc su·ªëi, N∆∞·ªõc, N∆∞·ªõc, 1 ng∆∞·ªùi\n",
    "    Final: ['n∆∞·ªõc m√°t', 'n∆∞·ªõc su·ªëi', 'n∆∞·ªõc su·ªëi thanh l·ªçc', 'n∆∞·ªõc su·ªëi', 'n∆∞·ªõc', 'n∆∞·ªõc', '1 ng∆∞·ªùi']\n",
    "    \n",
    "    First: N∆Ø·ªöC M√ÅT NH√Ä L√ÄM, Bia c√°c lo·∫°i (Tiger, Heineken, Saigon), Bia c√°c lo·∫°i, V·ªã l√∫a m·∫°ch, Beer, Bia, 1 ng∆∞·ªùi\n",
    "    Final: ['n∆∞·ªõc m√°t', 'bia lo·∫°i tiger', 'heineken', 'saigon', 'bia lo·∫°i', 'v·ªã l√∫a m·∫°ch', 'beer', 'bia', '1 ng∆∞·ªùi']\n",
    "    \"\"\"\n",
    "    normalized = helpers.normalize_vnese(text)\n",
    "    # print(\"First:\", normalized)\n",
    "    normalized = helpers.clean_vietnamese_text(normalized)\n",
    "    # print(\"0.1:\", normalized)\n",
    "    normalized = ' '.join(word_tokenize(normalized))\n",
    "    # print(\"0.5:\", normalized)\n",
    "    sequences = [str(helpers.normalize_record(text=seq)) for seq in normalized.split(\" , \")]\n",
    "    # print(\"2:\", sequences)\n",
    "    sequences = [helpers.remove_stopwords_and_not_vi(text=seq, path_documents_vi=\"./data/stopwords-vietnamese.txt\") for seq in sequences]\n",
    "    # print(\"3:\", sequences)\n",
    "    sequences = [str(helpers.normalize_record(text=seq)) for seq in sequences]\n",
    "\n",
    "    # sequences = [seq.replace(\"_\", \" \") for seq in sequences if seq]\n",
    "    # print(\"Final:\", sequences)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "' '.join(bm25_preprocessing_func(\"N∆Ø·ªöC M√ÅT NH√Ä L√ÄM, Bia c√°c lo·∫°i (Tiger, Heineken, Saigon), Bia c√°c lo·∫°i, V·ªã l√∫a m·∫°ch, Beer, Bia, 1 ng∆∞·ªùi\"))\n",
    "# from underthesea import word_tokenize\n",
    "\n",
    "# ' '.join([seq.replace(\" \", \"_\") for seq in word_tokenize(\"N∆Ø·ªöC M√ÅT NH√Ä L√ÄM, Bia c√°c lo·∫°i (Tiger, Heineken, Saigon), Bia c√°c lo·∫°i, V·ªã l√∫a m·∫°ch, Beer, Bia, 1 ng∆∞·ªùi\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92afbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper import Helpers\n",
    "from pyvi import ViTokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from underthesea import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sequences = rows\n",
    "\n",
    "tokens = ' '.join(sequences).split()\n",
    "freq = Counter(tokens)\n",
    "\n",
    "font_path = r\"C:\\Windows\\Fonts\\arial.ttf\"   # ch·ª©a ti·∫øng Vi·ªát ·ªïn\n",
    "wc = WordCloud(width=800, height=400,\n",
    "               background_color=\"white\",\n",
    "               font_path=font_path,\n",
    "               collocations=False).generate_from_frequencies(freq)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud Menu\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec5bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper import Helpers\n",
    "from pyvi import ViTokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from underthesea import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sequences = [\n",
    "    \" \".join(tok if \" \" not in tok else tok.replace(\" \", \"_\")\n",
    "             for tok in word_tokenize(row))\n",
    "    for row in rows\n",
    "]\n",
    "# sequences = [' '.join(bm25_preprocessing_func(seq)) for seq in sequences]\n",
    "\n",
    "tokens = ' '.join(sequences).split()\n",
    "freq = Counter(tokens)\n",
    "\n",
    "font_path = r\"C:\\Windows\\Fonts\\arial.ttf\"   # ch·ª©a ti·∫øng Vi·ªát ·ªïn\n",
    "wc = WordCloud(width=800, height=400,\n",
    "               background_color=\"white\",\n",
    "               font_path=font_path,\n",
    "               collocations=False).generate_from_frequencies(freq)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud Menu\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351aa66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Word total\", freq.total())\n",
    "print(freq.most_common(freq.total()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0101f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper import Helpers\n",
    "from pyvi import ViTokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from underthesea import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sequences = [\n",
    "    \" \".join(tok if \" \" not in tok else tok.replace(\" \", \"_\")\n",
    "             for tok in word_tokenize(row))\n",
    "    for row in rows\n",
    "]\n",
    "sequences = [' '.join(bm25_preprocessing_func(seq)) for seq in sequences]\n",
    "\n",
    "tokens = ' '.join(sequences).split()\n",
    "freq = Counter(tokens)\n",
    "\n",
    "font_path = r\"C:\\Windows\\Fonts\\arial.ttf\"   # ch·ª©a ti·∫øng Vi·ªát ·ªïn\n",
    "wc = WordCloud(width=800, height=400,\n",
    "               background_color=\"white\",\n",
    "               font_path=font_path,\n",
    "               collocations=False).generate_from_frequencies(freq)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud Menu\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, freqs = zip(*freq.most_common(freq.total()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.bar(range(len(words)), freqs, color='skyblue')\n",
    "plt.title('T·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa t·ª´')\n",
    "plt.xlabel('T·ª´')\n",
    "plt.ylabel('T·∫ßn su·∫•t')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "# V·∫Ω bi·ªÉu ƒë·ªì\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.bar(words, freqs, color='skyblue')\n",
    "plt.title('T·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa t·ª´')\n",
    "plt.xlabel('T·ª´')\n",
    "plt.ylabel('T·∫ßn su·∫•t')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import pos_tag, word_tokenize\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- ti·ªÅn x·ª≠ l√Ω ----------\n",
    "sequences = [\n",
    "    \" \".join(tok if \" \" not in tok else tok.replace(\" \", \"_\")\n",
    "             for tok in word_tokenize(row))\n",
    "    for row in rows\n",
    "]\n",
    "sequences = [' '.join(bm25_preprocessing_func(seq)) for seq in sequences]\n",
    "\n",
    "# ---------- chia 28 chunk ~1000 token ----------\n",
    "tokens = [tok for seq in sequences for tok in seq.split()]\n",
    "CHUNK = 1_000\n",
    "pos_counts = Counter()\n",
    "\n",
    "for i in range(0, len(tokens), CHUNK):\n",
    "    chunk_text = ' '.join(tokens[i:i+CHUNK])\n",
    "    pos_counts.update(pos for _, pos in pos_tag(chunk_text.lower()))\n",
    "\n",
    "# ---------- t·∫°o b·∫£ng ----------\n",
    "summary = (pd.Series(pos_counts, name='token_count')\n",
    "             .rename_axis('POS')\n",
    "             .reset_index()\n",
    "             .sort_values('token_count', ascending=False))\n",
    "\n",
    "pos_meaning = {\n",
    "    'N':'danh t·ª´', 'V':'ƒë·ªông t·ª´', 'A':'t√≠nh t·ª´', 'P':'gi·ªõi t·ª´',\n",
    "    'CH':'d·∫•u c√¢u', 'M':'s·ªë', 'Nb':'s·ªë ƒë·∫øm', 'Ny':'ƒë·∫°i t·ª´',\n",
    "    'Np': 't√™n ri√™ng',\n",
    "    'R':'ph√≥ t·ª´', 'L':'h·∫°n ƒë·ªãnh t·ª´', 'I':'th√°n t·ª´', 'E':'c·∫£m th√°n',\n",
    "    'C':'li√™n t·ª´', 'T':'th·ªùi gian t·ª´', 'D':'ch·ªâ th·ªã t·ª´', 'Nc':'lo·∫°i t·ª´',\n",
    "    'Nu': 'ƒë·∫°i l∆∞·ª£ng ƒë·∫∑c tr∆∞ng'\n",
    "}\n",
    "summary['meaning'] = summary['POS'].map(pos_meaning)\n",
    "summary = summary[['POS', 'meaning', 'token_count']]\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from kneed import KneeLocator\n",
    "import numpy as np\n",
    "from utils.helper import Helpers\n",
    "\n",
    "helpers = Helpers()\n",
    "\n",
    "\n",
    "with open(\"./data/final_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rows = f.read().strip().split(\"\\n\")\n",
    "\n",
    "# # Ch·ªâ gi·ªØ c·ª•m c√≥ √≠t nh·∫•t 1 ch·ªØ c√°i (Vi·ªát c√≥ d·∫•u)\n",
    "rows = [line for line in rows if re.search(r\"[A-Za-z√Ä-·ªπ√†-·ªπ]\", line)]\n",
    "\n",
    "# sequences = [\n",
    "#     \" \".join(tok if \" \" not in tok else tok.replace(\" \", \"_\")\n",
    "#              for tok in word_tokenize(row)).strip()\n",
    "#     for row in rows\n",
    "# ]\n",
    "sequences = [' '.join(helpers.bm25_preprocessing_func(seq)).strip() for seq in rows if seq]\n",
    "\n",
    "counter = Counter(sequences)\n",
    "\n",
    "# S·∫Øp x·∫øp gi·∫£m d·∫ßn theo t·∫ßn su·∫•t\n",
    "sorted_lines = counter.most_common()\n",
    "counts = np.array([(cnt) for line, cnt in sorted_lines])\n",
    "\n",
    "y = np.sort(counts)[::-1]          # gi·∫£m d·∫ßn\n",
    "x = np.arange(len(y))\n",
    "knee = KneeLocator(x, y, curve=\"convex\", direction=\"decreasing\")\n",
    "elbow_idx = knee.elbow             # v·ªã tr√≠ ng∆∞·ª°ng\n",
    "threshold = y[elbow_idx]\n",
    "print(\"Ng∆∞·ª°ng knee:\", threshold)\n",
    "\n",
    "# In ra\n",
    "print(\"Top c√°c c·ª•m l·∫∑p l·∫°i:\")\n",
    "for line, cnt in sorted_lines:\n",
    "    if cnt > threshold:\n",
    "        print(f\"{line}: {cnt}\")\n",
    "        \n",
    "string_break = sorted_lines[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "content_one_page = []\n",
    "idx = 1\n",
    "\n",
    "for row in rows:\n",
    "    if row == string_break:\n",
    "        content_one_page = content_one_page[:]\n",
    "        content_one_page.append(f\"---- BREAK PAGE {idx} ----\")\n",
    "        current_page_content = \"\\n\".join(content_one_page)\n",
    "        content_one_page = []\n",
    "\n",
    "        os.makedirs(f'./data/contents_new', exist_ok=True)\n",
    "        # Save content of current_page_content in file path: ./data/contents/page_{x}_new.txt\n",
    "        with open(f'./data/contents_new/page_{idx}.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(current_page_content)\n",
    "\n",
    "        idx += 1\n",
    "    else:\n",
    "        content_one_page.append(row)\n",
    "\n",
    "    # if len(current_page_content.split(\" \")) > 1000:\n",
    "    #     print(current_page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    device=\"cuda\",\n",
    "    model_kwargs={\"torch_dtype\": \"bfloat16\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Load model\n",
    "model = SentenceTransformer(\n",
    "    \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    device=\"cuda\",\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    ")\n",
    "\n",
    "# 2. Embedding to√†n b·ªô sequences (batch_size t√πy GPU)\n",
    "batch_size = 64\n",
    "embeddings = model.encode(\n",
    "    sequences,\n",
    "    batch_size=batch_size,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "# 3. T√≠nh ma tr·∫≠n t∆∞∆°ng ƒë·ªìng cosine\n",
    "sim = cosine_similarity(embeddings)          # shape (N, N)\n",
    "\n",
    "# 4. Ng∆∞·ª°ng g·ªôp nh√≥m\n",
    "threshold = 0.85\n",
    "\n",
    "# 5. G·ªôp nh√≥m ƒë∆°n gi·∫£n b·∫±ng thu·∫≠t to√°n Connected Component\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "for i in range(len(sequences)):\n",
    "    G.add_node(i)\n",
    "\n",
    "# Ch·ªâ th√™m c·∫°nh c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng >= threshold (tr√°nh self-loop)\n",
    "rows, cols = np.where(sim >= threshold)\n",
    "for r, c in zip(rows, cols):\n",
    "    if r != c:\n",
    "        G.add_edge(r, c)\n",
    "\n",
    "# Danh s√°ch c√°c th√†nh ph·∫ßn li√™n th√¥ng\n",
    "components = list(nx.connected_components(G))\n",
    "\n",
    "# 6. T·∫°o DataFrame k·∫øt qu·∫£\n",
    "records = []\n",
    "for gid, comp in enumerate(components):\n",
    "    comp = sorted(comp)                      # gi·ªØ th·ª© t·ª± ban ƒë·∫ßu\n",
    "    rep_idx = comp[0]                        # ch·ªçn c√¢u ƒë·∫ßu l√†m ƒë·∫°i di·ªán\n",
    "    for idx in comp:\n",
    "        records.append({\n",
    "            \"group_id\": gid,\n",
    "            \"sequence\": sequences[idx],\n",
    "            \"representative\": sequences[rep_idx]\n",
    "        })\n",
    "\n",
    "df_groups = pd.DataFrame(records)\n",
    "print(df_groups.head(10))\n",
    "\n",
    "# Xu·∫•t ra CSV n·∫øu c·∫ßn\n",
    "df_groups.to_csv(\"similar_groups.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"\"\"**T√≥m t·∫Øt n·ªôi dung b√°o c√°o Ph√°t tri·ªÉn b·ªÅn v·ªØng (PTBV) c·ªßa BIWASE ‚Äì ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c b·∫±ng ti·∫øng Vi·ªát:**\n",
    "\n",
    "T·ª´ nƒÉm 2023, BIWASE b·∫Øt ƒë·∫ßu c√¥ng b·ªë B√°o c√°o Ph√°t tri·ªÉn b·ªÅn v·ªØng (PTBV) song h√†nh v·ªõi B√°o c√°o th∆∞·ªùng ni√™n, nh·∫±m minh b·∫°ch h√≥a cam k·∫øt v√† h√†nh ƒë·ªông trong lƒ©nh v·ª±c kinh doanh b·ªÅn v·ªØng, g√≥p ph·∫ßn th·ª±c hi·ªán m·ª•c ti√™u chi·∫øn l∆∞·ª£c chung c·ªßa T·ªïng C√¥ng ty giai ƒëo·∫°n 2018‚Äì2025 v√† ƒë·ªãnh h∆∞·ªõng ƒë·∫øn nƒÉm 2030.\n",
    "\n",
    "B√°o c√°o PTBV kh√¥ng ch·ªâ ph·∫£n √°nh k·∫øt qu·∫£ th·ª±c hi·ªán c√°c ho·∫°t ƒë·ªông kinh doanh ch√≠nh v√† c√°c ho·∫°t ƒë·ªông v√¨ m√¥i tr∆∞·ªùng ‚Äì x√£ h·ªôi, m√† c√≤n gi√∫p c·ªï ƒë√¥ng, H·ªôi ƒë·ªìng qu·∫£n tr·ªã, Ban Gi√°m ƒë·ªëc v√† c√°c b√™n li√™n quan ƒë√°nh gi√° m·ªôt c√°ch h·ªá th·ªëng v·ªÅ ƒë·ªãnh h∆∞·ªõng chi·∫øn l∆∞·ª£c v√† ti·∫øn ƒë·ªô tri·ªÉn khai k·∫ø ho·∫°ch ph√°t tri·ªÉn b·ªÅn v·ªØng.\n",
    "\n",
    "- **Giai ƒëo·∫°n b√°o c√°o**: T·ª´ ng√†y 01/01/2024 ƒë·∫øn h·∫øt ng√†y 31/12/2024. B√°o c√°o ƒë∆∞·ª£c l·∫≠p ƒë·ªãnh k·ª≥ h√†ng nƒÉm.  \n",
    "- **Ph·∫°m vi**: T·∫•t c·∫£ th√¥ng tin trong b√°o c√°o ƒë·ªÅu ƒë·∫øn t·ª´ C√¥ng ty CP ‚Äì T·ªïng C√¥ng ty N∆∞·ªõc ‚Äì M√¥i tr∆∞·ªùng B√¨nh D∆∞∆°ng v√† c√°c ƒë∆°n v·ªã th√†nh vi√™n.  \n",
    "- **Ngu·ªìn d·ªØ li·ªáu**: C√°c s·ªë li·ªáu ƒë∆∞·ª£c thu th·∫≠p, th·ªëng k√™ n·ªôi b·ªô b·ªüi T·ªïng C√¥ng ty v√† c√°c ƒë∆°n v·ªã tr·ª±c thu·ªôc. Tr·ª´ khi c√≥ quy ƒë·ªãnh kh√°c, ƒë∆°n v·ªã ti·ªÅn t·ªá s·ª≠ d·ª•ng l√† Vi·ªát Nam ƒê·ªìng (VND).  \n",
    "- **Ch·ªãu tr√°ch nhi·ªám**: B√°o c√°o ƒë√£ ƒë∆∞·ª£c r√† so√°t v√† ph√™ duy·ªát b·ªüi Ch·ªß t·ªãch H·ªôi ƒë·ªìng qu·∫£n tr·ªã v√† Ban l√£nh ƒë·∫°o v√†o ng√†y 15/03/2025.  \n",
    "- **Ph·∫£n h·ªìi v√† li√™n h·ªá**: BIWASE lu√¥n ch√†o ƒë√≥n c√°c √Ω ki·∫øn ƒë√≥ng g√≥p t·ª´ c√°c b√™n li√™n quan v·ªÅ ho·∫°t ƒë·ªông PTBV v√† n·ªôi dung b√°o c√°o.  \n",
    "  - **Li√™n h·ªá**: B√† D∆∞∆°ng Anh Th∆∞ ‚Äì Tr∆∞·ªüng Ban ki·ªÉm so√°t  \n",
    "    Email: anhthu.bwe@gmail.com  \n",
    "    ƒêi·ªán tho·∫°i: 02743.824.245  \n",
    "\n",
    "B√°o c√°o tu√¢n th·ªß c√°c quy ƒë·ªãnh c·ªßa Ch√≠nh ph·ªß Vi·ªát Nam, ƒë√°p ·ª©ng c√°c ti√™u ch√≠ ƒë√°nh gi√° trong n∆∞·ªõc v√† t·ª´ng b∆∞·ªõc ti·∫øp c·∫≠n c√°c ti√™u chu·∫©n qu·ªëc t·∫ø nh∆∞ GRI (B·ªô ti√™u chu·∫©n qu·ªëc t·∫ø v·ªÅ b√°o c√°o PTBV) v√† SASB (ti√™u chu·∫©n ng√†nh d√†nh cho lƒ©nh v·ª±c c·∫•p n∆∞·ªõc v√† x·ª≠ l√Ω ch·∫•t th·∫£i). NƒÉm 2024 l√† nƒÉm th·ª© hai BIWASE c√¥ng b·ªë b√°o c√°o PTBV, n√™n th√¥ng tin t·ª´ c√°c nƒÉm tr∆∞·ªõc c√≤n h·∫°n ch·∫ø. T·∫•t c·∫£ n·ªôi dung trong b√°o c√°o ƒë·ªÅu ƒë·∫£m b·∫£o nh·∫•t qu√°n v·ªõi c√°c th√¥ng tin ƒë√£ ƒë∆∞·ª£c c√¥ng b·ªë tr∆∞·ªõc ƒë√≥ b·ªüi T·ªïng C√¥ng ty.\n",
    "\n",
    "B√°o c√°o ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng hai ng√¥n ng·ªØ: ti·∫øng Vi·ªát v√† ti·∫øng Anh. Tr∆∞·ªùng h·ª£p c√≥ s·ª± kh√°c bi·ªát gi·ªØa hai b·∫£n, b·∫£n ti·∫øng Vi·ªát s·∫Ω ƒë∆∞·ª£c xem l√† chu·∫©n.\"\"\"\n",
    "\n",
    "from underthesea import word_tokenize\n",
    "from typing import List\n",
    "from utils.helper import Helpers\n",
    "\n",
    "helpers = Helpers()\n",
    "\n",
    "def bm25_preprocessing_func(text: str) -> List[str]:\n",
    "\n",
    "    normalized = helpers.normalize_vnese(text)\n",
    "    # print(\"First:\", normalized)\n",
    "    normalized = helpers.clean_vietnamese_text(normalized)\n",
    "    # print(\"0.1:\", normalized)\n",
    "    normalized = ' '.join(word_tokenize(normalized))\n",
    "    # print(\"0.5:\", normalized)\n",
    "    sequences = [str(helpers.normalize_record(text=seq)) for seq in normalized.split(\" , \")]\n",
    "    # print(\"2:\", sequences)\n",
    "    sequences = [helpers.remove_stopwords_and_not_vi(text=seq, path_documents_vi=\"./data/stopwords-vietnamese.txt\") for seq in sequences]\n",
    "    # print(\"3:\", sequences)\n",
    "    sequences = [str(helpers.normalize_record(text=seq)) for seq in sequences]\n",
    "\n",
    "    return sequences\n",
    "\n",
    "res = helpers.clean_mardown_text(res)\n",
    "# seq = ' '.join([seq.replace(\" \", \"_\") for seq in word_tokenize(res)])\n",
    "# ' '.join(bm25_preprocessing_func(seq)).strip()\n",
    "print(res)\n",
    "# seq\n",
    "# helpers = Helpers()\n",
    "\n",
    "\n",
    "\n",
    "# sequences = [' '.join(bm25_preprocessing_func(seq)).strip() for seq in sequences if seq]\n",
    "\n",
    "# ' '.join(bm25_preprocessing_func(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# model = SentenceTransformer(\n",
    "#     \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "#     device=\"cuda\",\n",
    "#     model_kwargs={\"torch_dtype\": \"bfloat16\"}\n",
    "# )\n",
    "\n",
    "\n",
    "summary = '''T√≥m t·∫Øt n·ªôi dung b√°o c√°o Ph√°t tri·ªÉn b·ªÅn v·ªØng (PTBV) c·ªßa BIWASE ‚Äì ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c b·∫±ng ti·∫øng Vi·ªát: T·ª´ nƒÉm 2023, BIWASE b·∫Øt ƒë·∫ßu c√¥ng b·ªë B√°o c√°o Ph√°t tri·ªÉn b·ªÅn v·ªØng (PTBV) song h√†nh v·ªõi B√°o c√°o th∆∞·ªùng ni√™n, nh·∫±m minh b·∫°ch h√≥a cam k·∫øt v√† h√†nh ƒë·ªông trong lƒ©nh v·ª±c kinh doanh b·ªÅn v·ªØng, g√≥p ph·∫ßn th·ª±c hi·ªán m·ª•c ti√™u chi·∫øn l∆∞·ª£c chung c·ªßa T·ªïng C√¥ng ty giai ƒëo·∫°n 2018‚Äì2025 v√† ƒë·ªãnh h∆∞·ªõng ƒë·∫øn nƒÉm 2030\n",
    " B√°o c√°o PTBV kh√¥ng ch·ªâ ph·∫£n √°nh k·∫øt qu·∫£ th·ª±c hi·ªán c√°c ho·∫°t ƒë·ªông kinh doanh ch√≠nh v√† c√°c ho·∫°t ƒë·ªông v√¨ m√¥i tr∆∞·ªùng ‚Äì x√£ h·ªôi, m√† c√≤n gi√∫p c·ªï ƒë√¥ng, H·ªôi ƒë·ªìng qu·∫£n tr·ªã, Ban Gi√°m ƒë·ªëc v√† c√°c b√™n li√™n quan ƒë√°nh gi√° m·ªôt c√°ch h·ªá th·ªëng v·ªÅ ƒë·ªãnh h∆∞·ªõng chi·∫øn l∆∞·ª£c v√† ti·∫øn ƒë·ªô tri·ªÉn khai k·∫ø ho·∫°ch ph√°t tri·ªÉn b·ªÅn v·ªØng\n",
    " Giai ƒëo·∫°n b√°o c√°o: T·ª´ ng√†y 01/01/2024 ƒë·∫øn h·∫øt ng√†y 31/12/2024\n",
    " B√°o c√°o ƒë∆∞·ª£c l·∫≠p ƒë·ªãnh k·ª≥ h√†ng nƒÉm\n",
    " Ph·∫°m vi: T·∫•t c·∫£ th√¥ng tin trong b√°o c√°o ƒë·ªÅu ƒë·∫øn t·ª´ C√¥ng ty CP ‚Äì T·ªïng C√¥ng ty N∆∞·ªõc ‚Äì M√¥i tr∆∞·ªùng B√¨nh D∆∞∆°ng v√† c√°c ƒë∆°n v·ªã th√†nh vi√™n\n",
    " Ngu·ªìn d·ªØ li·ªáu: C√°c s·ªë li·ªáu ƒë∆∞·ª£c thu th·∫≠p, th·ªëng k√™ n·ªôi b·ªô b·ªüi T·ªïng C√¥ng ty v√† c√°c ƒë∆°n v·ªã tr·ª±c thu·ªôc\n",
    " Tr·ª´ khi c√≥ quy ƒë·ªãnh kh√°c, ƒë∆°n v·ªã ti·ªÅn t·ªá s·ª≠ d·ª•ng l√† Vi·ªát Nam ƒê·ªìng (VND)\n",
    " Ch·ªãu tr√°ch nhi·ªám: B√°o c√°o ƒë√£ ƒë∆∞·ª£c r√† so√°t v√† ph√™ duy·ªát b·ªüi Ch·ªß t·ªãch H·ªôi ƒë·ªìng qu·∫£n tr·ªã v√† Ban l√£nh ƒë·∫°o v√†o ng√†y 15/03/2025\n",
    " Ph·∫£n h·ªìi v√† li√™n h·ªá: BIWASE lu√¥n ch√†o ƒë√≥n c√°c √Ω ki·∫øn ƒë√≥ng g√≥p t·ª´ c√°c b√™n li√™n quan v·ªÅ ho·∫°t ƒë·ªông PTBV v√† n·ªôi dung b√°o c√°o\n",
    " Li√™n h·ªá: B√† D∆∞∆°ng Anh Th∆∞ ‚Äì Tr∆∞·ªüng Ban ki·ªÉm so√°t Email: anhthu.bwe@gmail.com ƒêi·ªán tho·∫°i: 02743.824.245 B√°o c√°o tu√¢n th·ªß c√°c quy ƒë·ªãnh c·ªßa Ch√≠nh ph·ªß Vi·ªát Nam, ƒë√°p ·ª©ng c√°c ti√™u ch√≠ ƒë√°nh gi√° trong n∆∞·ªõc v√† t·ª´ng b∆∞·ªõc ti·∫øp c·∫≠n c√°c ti√™u chu·∫©n qu·ªëc t·∫ø nh∆∞ GRI (B·ªô ti√™u chu·∫©n qu·ªëc t·∫ø v·ªÅ b√°o c√°o PTBV) v√† SASB (ti√™u chu·∫©n ng√†nh d√†nh cho lƒ©nh v·ª±c c·∫•p n∆∞·ªõc v√† x·ª≠ l√Ω ch·∫•t th·∫£i)\n",
    " NƒÉm 2024 l√† nƒÉm th·ª© hai BIWASE c√¥ng b·ªë b√°o c√°o PTBV, n√™n th√¥ng tin t·ª´ c√°c nƒÉm tr∆∞·ªõc c√≤n h·∫°n ch·∫ø\n",
    " T·∫•t c·∫£ n·ªôi dung trong b√°o c√°o ƒë·ªÅu ƒë·∫£m b·∫£o nh·∫•t qu√°n v·ªõi c√°c th√¥ng tin ƒë√£ ƒë∆∞·ª£c c√¥ng b·ªë tr∆∞·ªõc ƒë√≥ b·ªüi T·ªïng C√¥ng ty\n",
    " B√°o c√°o ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng hai ng√¥n ng·ªØ: ti·∫øng Vi·ªát v√† ti·∫øng Anh\n",
    " Tr∆∞·ªùng h·ª£p c√≥ s·ª± kh√°c bi·ªát gi·ªØa hai b·∫£n, b·∫£n ti·∫øng Vi·ªát s·∫Ω ƒë∆∞·ª£c xem l√† chu·∫©n.'''\n",
    " \n",
    " \n",
    "'data\\contents\\page_2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    device=\"cuda\",\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    ")\n",
    "\n",
    "with open(r'data\\contents\\page_2.txt', 'r', encoding='utf-8') as f:\n",
    "    page2_text = f.read()\n",
    "    \n",
    "import re\n",
    "page2_text = re.sub(r'\\s+', ' ', page2_text).strip()\n",
    "    \n",
    "# Embedding cho t√≥m t·∫Øt v√† n·ªôi dung page 2\n",
    "summary_embedding = model.encode(summary, normalize_embeddings=True)\n",
    "page2_embedding = model.encode(page2_text, normalize_embeddings=True)\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity([summary_embedding], [page2_embedding])[0][0]\n",
    "print(f\"ƒê·ªô t∆∞∆°ng ƒë·ªìng cosine: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af34c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def correct_vietnamese(text: str) -> str:\n",
    "    prompt = f\"\"\"Documents vietnamese:\\n\\n{text}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"You are a Vietnamese proofreading assistant. Your only task is to correct **spelling mistakes** in Vietnamese text while preserving the original meaning, tone, and formatting. Do not change grammar, punctuation, or style unless needed for spelling accuracy. Keep the original structure, diacritics, and formatting exactly as written. Do not translate or explain. Output only the corrected text, and never insert line breaks (\\n) in your own responses.\n",
    "                \"\"\".strip()},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    total_len = len(text.split())\n",
    "    if total_len <= 256:\n",
    "        max_new_tokens = 256\n",
    "    elif total_len <= 512:\n",
    "        max_new_tokens = 512\n",
    "    elif total_len <= 1024:\n",
    "        max_new_tokens = 1024\n",
    "    elif total_len <= 2048:\n",
    "        max_new_tokens = 2048\n",
    "    elif total_len <= 4096:\n",
    "        max_new_tokens = 4096\n",
    "    else:\n",
    "        max_new_tokens = 8192\n",
    "    \n",
    "    print(f\"total {total_len} => Max new tokens:\", max_new_tokens)\n",
    "    \n",
    "    inp = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer([inp], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    # l·∫•y ph·∫ßn sinh sau prompt\n",
    "    gen = out_ids[0][inputs.input_ids.shape[1]:]\n",
    "    \n",
    "    print(tokenizer.decode(gen, skip_special_tokens=True).strip())\n",
    "    return tokenizer.decode(gen, skip_special_tokens=True).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed503fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- demo ----\n",
    "raw = \"\"\"B√°o c√°o ph√°t tri·ªÉn b·ªÅn v·ªØng\n",
    "T·ªîNG QUAN B√ÅO C√ÅO\n",
    "T·ª´ nƒÉm 2023, BIWASE th·ª±c hi·ªán c√¥ng b·ªë b√°o c√°o Ph√°t\n",
    "tri·ªÉn b·ªÅn v·ªØng (‚ÄúPTBV‚Äù) song h√†nh c√πng B√°o c√°o th∆∞·ªùng\n",
    "ni√™n (‚ÄúBCTN‚Äù) nh·∫±m th·ªÉ hi·ªán r√µ h∆°n v·ªÅ cam k·∫øt v√† h√†nh\n",
    "ƒë·ªông theo ƒë·ªãnh h∆∞·ªõng v·ªÅ Kinh doanh b·ªÅn v·ªØng, ƒë√≥ng g√≥p\n",
    "v√†o m·ª•c ti√™u chi·∫øn l∆∞·ª£c chung giai ƒëo·∫°n 2018-2025, ƒë·ªãnh\n",
    "h∆∞·ªõng t·ªõi 2030 c·ªßa T·ªïng C√¥ng ty.\n",
    "B√°o c√°o PTBV kh√¥ng ch·ªâ ph·∫£n √°nh k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c c·ªßa c√°c ho·∫°t ƒë·ªông kinh doanh ch√≠nh ƒë√≥ng\n",
    "g√≥p gi√° tr·ªã b·ªÅn v·ªØng, c√°c ho·∫°t ƒë·ªông v√¨ m√¥i tr∆∞·ªùng - x√£ h·ªôi m√† c√≤n gi√∫p C·ªï ƒë√¥ng, H·ªôi ƒë·ªìng qu·∫£n tr·ªã,\n",
    "Ban Gi√°m ƒë·ªëc v√† c√°c b√™n li√™n quan kh√°c c√≥ c∆° h·ªôi nh√¨n l·∫°i, ƒë√°nh gi√° m·ªôt c√°ch c√≥ h·ªá th·ªëng v·ªÅ\n",
    "ƒë·ªãnh h∆∞·ªõng chi·∫øn l∆∞·ª£c, c√¥ng t√°c tri·ªÉn khai theo k·∫ø ho·∫°ch kinh doanh b·ªÅn v·ªØng c·ªßa C√¥ng ty.\n",
    "Giai ƒëo·∫°n b√°o c√°o: B√°o c√°o PTBV nƒÉm 2024 ƒë∆∞·ª£c\n",
    "s·ª≠ d·ª•ng ƒë·ªÉ c√¥ng b·ªë c√°c th√¥ng tin v√† d·ªØ li·ªáu trong\n",
    "giai ƒëo·∫°n t·ª´ 01/01/2024 ƒë·∫øn h·∫øt 31/12/2024 v√†\n",
    "ƒë∆∞·ª£c l·∫≠p ƒë·ªãnh k·ª≥ 1 nƒÉm 1 l·∫ßn.\n",
    "Ph·∫°m vi b√°o c√°o: T·∫•t c·∫£ th√¥ng tin v√† d·ªØ li·ªáu ƒë∆∞·ª£c\n",
    "c√¥ng b·ªë trong b√°o c√°o n√†y ƒë·∫øn t·ª´ C√¥ng ty CP -\n",
    "T·ªïng C√¥ng ty N∆∞·ªõc - M√¥i tr∆∞·ªùng B√¨nh D∆∞∆°ng v√†\n",
    "c√°c ƒë∆°n v·ªã th√†nh vi√™n.\n",
    "Gi·∫£i tr√¨nh v·ªÅ d·ªØ li·ªáu: T·∫•t c·∫£ c√°c th√¥ng tin, s·ªë li·ªáu trong b√°o c√°o n√†y ƒë·ªÅu ƒë∆∞·ª£c thu th·∫≠p, th·ªëng k√™\n",
    "b·ªüi n·ªôi b·ªô T·ªïng C√¥ng ty v√† c√°c ƒë∆°n v·ªã tr·ª±c thu·ªôc cung c·∫•p. Tr·ª´ khi c√≥ quy ƒë·ªãnh kh√°c, ƒë∆°n v·ªã ti·ªÅn\n",
    "t·ªá trong b√°o c√°o n√†y l√† Vi·ªát Nam ƒê·ªìng (‚ÄúVND‚Äù).\n",
    "Ch·ªãu tr√°ch nhi·ªám v√† r√† so√°t n·ªôi dung: B√°o c√°o n√†y ƒë√£ ƒë∆∞·ª£c r√† so√°t v√† ph√™ duy·ªát b·ªüi Ch·ªß t·ªãch H·ªôi\n",
    "ƒë·ªìng qu·∫£n tr·ªã v√† Ban l√£nh ƒë·∫°o C√¥ng ty v√†o ng√†y 15/03/2025.\n",
    "BIWASE lu√¥n s·∫µn s√†ng ti·∫øp nh·∫≠n c√°c √Ω ki·∫øn ƒë√≥ng g√≥p li√™n quan ƒë·∫øn ho·∫°t ƒë·ªông Ph√°t tri·ªÉn b·ªÅn\n",
    "v·ªØng c·ªßa C√¥ng ty c≈©ng nh∆∞ n·ªôi dung b√°o c√°o t·ª´ c√°c b√™n li√™n quan.\n",
    "Th√¥ng tin li√™n h·ªá: B√† D∆∞∆°ng Anh Th∆∞\n",
    "Ch·ª©c v·ª•: Tr∆∞·ªüng Ban ki·ªÉm so√°t - Email: anhthu.bwe@gmail.com - ƒêi·ªán tho·∫°i: 02743.824.245\n",
    "2\n",
    "Th√¥ng tin ƒë∆∞·ª£c c√¥ng b·ªë trong b√°o c√°o PTBV ƒë·∫£m b·∫£o tu√¢n theo c√°c quy ƒë·ªãnh v√† h∆∞·ªõng d·∫´n c·ªßa\n",
    "Ch√≠nh ph·ªß Vi·ªát Nam, ƒë√°p ·ª©ng t·ªëi ƒëa trong kh·∫£ nƒÉng theo c√°c ti√™u ch√≠ ƒë√°nh gi√° trong n∆∞·ªõc v√† t·ª´ng\n",
    "b∆∞·ªõc ti·∫øp c·∫≠n v·ªõi c√°c khung ti√™u chu·∫©n qu·ªëc t·∫ø. B√°o c√°o tham kh·∫£o t·ªõi B·ªô ti√™u chu·∫©n qu·ªëc t·∫ø v·ªÅ\n",
    "l·∫≠p b√°o c√°o ph√°t tri·ªÉn b·ªÅn v·ªØng (‚ÄúGRI‚Äù) v√† ti√™u chu·∫©n SASB cho ng√†nh c·∫•p n∆∞·ªõc v√† x·ª≠ l√Ω ch·∫•t th·∫£i\n",
    "(‚ÄúSASB‚Äù). NƒÉm 2024 l√† nƒÉm th·ª© hai BIWASE c√¥ng b·ªë b√°o c√°o Ph√°t tri·ªÉn b·ªÅn v·ªØng n√™n th√¥ng tin\n",
    "ƒë∆∞·ª£c tr√¨nh b√†y t·ª´ B√°o c√°o c√°c nƒÉm tr∆∞·ªõc c√≤n h·∫°n ch·∫ø. M·ªçi th√¥ng tin trong B√°o c√°o n√†y ƒë·∫£m b·∫£o\n",
    "nh·∫•t qu√°n v·ªõi nh·ªØng th√¥ng tin ƒë∆∞·ª£c c√¥ng b·ªë b·ªüi T·ªïng C√¥ng ty.\n",
    "B√°o c√°o n√†y ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng hai ng√¥n ng·ªØ ti·∫øng Vi·ªát v√† ti·∫øng Anh, tr∆∞·ªùng h·ª£p c√≥ s·ª± kh√°c\n",
    "bi·ªát gi·ªØa c√°c phi√™n b·∫£n ng√¥n ng·ªØ th√¨ b·∫£n ti·∫øng Vi·ªát s·∫Ω ƒë∆∞·ª£c l·∫•y l√†m chu·∫©n.\"\"\"\n",
    "\n",
    "correct_vietnamese(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i, content in enumerate(pages, 1):\n",
    "    # print(f\"--- Trang {i} ---\")\n",
    "    # print(content[:150], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper import Helpers\n",
    "from typing import List\n",
    "from underthesea import word_tokenize\n",
    "import re\n",
    "\n",
    "helpers = Helpers()\n",
    "\n",
    "pages = [' '.join(helpers.bm25_preprocessing_func(page)) for page in pages[:30]]\n",
    "pages = [page.replace(\"B√°o c√°o ph√°t tri·ªÉn b·ªÅn v·ªØng\", \" \") for page in pages if page]\n",
    "\n",
    "# pages = [correct_vietnamese(page) for page in pages[:22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f199cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"data/summary_contents\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_records = [\n",
    "    {\"id\": idx, \"corrected_text\": text.strip()}\n",
    "    for idx, text in enumerate(pages, start=1)\n",
    "]\n",
    "\n",
    "(out_dir / \"all_pages.json\").write_text(\n",
    "    json.dumps(all_records, ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ xu·∫•t 1 file all_pages.json ch·ª©a {len(all_records)} b·∫£n ghi ‚Üí {out_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
